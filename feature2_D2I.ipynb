{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfor(dataset):\n",
    "    im = np.zeros([9, 9])\n",
    "    im[0, 3] = dataset[0]\n",
    "    im[0, 4] = dataset[1]\n",
    "    im[0, 5] = dataset[2]\n",
    "    \n",
    "    im[1, 3] = dataset[3]\n",
    "    im[1, 5] = dataset[4]\n",
    "\n",
    "    im[2, 0] = dataset[5]\n",
    "    im[2, 1] = dataset[6]\n",
    "    im[2, 2] = dataset[7]\n",
    "    im[2, 3] = dataset[8]\n",
    "    im[2, 4] = dataset[9]\n",
    "    im[2, 5] = dataset[10]\n",
    "    im[2, 6] = dataset[11]\n",
    "    im[2, 7] = dataset[12]\n",
    "    im[2, 8] = dataset[13]\n",
    "\n",
    "    im[3, 0] = dataset[14]\n",
    "    im[3, 1] = dataset[15]\n",
    "    im[3, 2] = dataset[16]\n",
    "    im[3, 3] = dataset[17]\n",
    "    im[3, 4] = dataset[18]\n",
    "    im[3, 5] = dataset[19]\n",
    "    im[3, 6] = dataset[20]\n",
    "    im[3, 7] = dataset[21]\n",
    "    im[3, 8] = dataset[22]\n",
    "\n",
    "    im[4, 0] = dataset[23]\n",
    "    im[4, 1] = dataset[24]\n",
    "    im[4, 2] = dataset[25]\n",
    "    im[4, 3] = dataset[26]\n",
    "    im[4, 4] = dataset[27]\n",
    "    im[4, 5] = dataset[28]\n",
    "    im[4, 6] = dataset[29]\n",
    "    im[4, 7] = dataset[30]\n",
    "    im[4, 8] = dataset[31]\n",
    "\n",
    "    im[5, 0] = dataset[32]\n",
    "    im[5, 1] = dataset[33]\n",
    "    im[5, 2] = dataset[34]\n",
    "    im[5, 3] = dataset[35]\n",
    "    im[5, 4] = dataset[36]\n",
    "    im[5, 5] = dataset[37]\n",
    "    im[5, 6] = dataset[38]\n",
    "    im[5, 7] = dataset[39]\n",
    "    im[5, 8] = dataset[40]\n",
    "\n",
    "    im[6, 0] = dataset[41]\n",
    "    im[6, 1] = dataset[42]\n",
    "    im[6, 2] = dataset[43]\n",
    "    im[6, 3] = dataset[44]\n",
    "    im[6, 4] = dataset[45]\n",
    "    im[6, 5] = dataset[46]\n",
    "    im[6, 6] = dataset[47]\n",
    "    im[6, 7] = dataset[48]\n",
    "    im[6, 8] = dataset[49]\n",
    "\n",
    "    im[7, 1] = dataset[50]\n",
    "    im[7, 2] = dataset[51]\n",
    "    im[7, 3] = dataset[52]\n",
    "    im[7, 4] = dataset[53]\n",
    "    im[7, 5] = dataset[54]\n",
    "    im[7, 6] = dataset[55]\n",
    "    im[7, 7] = dataset[56]\n",
    "\n",
    "    im[8, 2] = dataset[57]\n",
    "    im[8, 3] = dataset[58]\n",
    "    im[8, 4] = dataset[59]\n",
    "    im[8, 5] = dataset[60]\n",
    "    im[8, 6] = dataset[61]\n",
    "\n",
    "    im = im.reshape(im.shape[0], im.shape[1], 1)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(fromIndex, toIndex):\n",
    "        label = scipy.io.loadmat(\"./data/SEED1/processed_data/label.mat\")[\"label\"]\n",
    "        return label[0][fromIndex:toIndex]+1\n",
    "    \n",
    "def load_dataset(fromIndex, toIndex, featurename):\n",
    "        files = os.listdir(\"./data/SEED1/processed_data/data\")\n",
    "        labellist = load_label(fromIndex, toIndex) \n",
    "\n",
    "        data = []\n",
    "        labels = []\n",
    "        for fileName in files:\n",
    "            for index in range(fromIndex, toIndex):\n",
    "                feats = scipy.io.loadmat(\"./data/SEED1/processed_data/data/\" + fileName)[featurename + str(index+1)]\n",
    "                feats = feats.transpose()\n",
    "\n",
    "                label = labellist[index - fromIndex]\n",
    "\n",
    "                for j in range(feats.shape[1]):\n",
    "                    data1 = []\n",
    "                    for i in range(feats.shape[0]):\n",
    "                        data1 = np.append(data1, feats[i][j])\n",
    "                    data.append(data1)\n",
    "                    labels.append(label)\n",
    "        dataset = np.array(data)\n",
    "        labels = np.array(labels)\n",
    "        return dataset, labels \n",
    "    \n",
    "def loaddata():\n",
    "    train_data, train_label = load_dataset(0, 15, 'de_LDS')\n",
    "\n",
    "    return train_data, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2img(datarow):\n",
    "    f0 = transfor(datarow[:62])\n",
    "    f1 = transfor(datarow[62:124])\n",
    "    f2 = transfor(datarow[124:186])\n",
    "    f3 = transfor(datarow[186:248])\n",
    "    f4 = transfor(datarow[248:310])\n",
    "    \n",
    "    image = np.concatenate((f0, f1, f2, f3, f4), axis=2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(d,l):\n",
    "    images = []\n",
    "    labels = []\n",
    "    min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "    d = min_max_scaler.fit_transform(d.T).transpose()\n",
    "    for i in range(d.shape[0]):\n",
    "        label = l[i]\n",
    "        image = convert2img(d[i])\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "def picklefile(file, data):\n",
    "    with open(file,'wb') as f:\n",
    "        pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label = loaddata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, train_labels = convert(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142548, 9, 9, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.permutation(len(train_imgs))\n",
    "train_imgs, train_labels = train_imgs[idx], train_labels[idx]\n",
    "train_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./data/SEED1/feature2_imgs\")\n",
    "traininfo = {'':'', 'data':train_imgs, 'label': train_labels}\n",
    "picklefile(r'./data/SEED1/feature2_imgs/train_images', traininfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
